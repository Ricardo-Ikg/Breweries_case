# ğŸº Breweries Data Engineering Case

Este repositÃ³rio contÃ©m a soluÃ§Ã£o para o **BEES Data Engineering â€“ Breweries Case**, cujo objetivo Ã© demonstrar a construÃ§Ã£o de um pipeline de dados completo a partir do consumo de uma API pÃºblica, seguindo o padrÃ£o de **arquitetura Medallion (Bronze / Silver / Gold)**, com orquestraÃ§Ã£o, testes e documentaÃ§Ã£o adequada îˆ€fileciteîˆ‚turn0file0îˆ.

---

## ğŸ¯ Objetivo do Case

O objetivo do projeto Ã©:

* Consumir dados da **Open Brewery DB API**
* Persistir os dados em um *data lake* seguindo o padrÃ£o **Medallion Architecture**
* Orquestrar o pipeline utilizando uma ferramenta de mercado
* Aplicar transformaÃ§Ãµes, qualidade de dados e agregaÃ§Ãµes
* Disponibilizar uma camada analÃ­tica pronta para consumo

---

## ğŸ§© VisÃ£o Geral da Arquitetura

O pipeline foi desenhado seguindo o conceito de camadas de dados (*Medallion Architecture*), com responsabilidades bem definidas, baixo acoplamento entre etapas e foco em reprocessamento e confiabilidade.

### ğŸ“ Diagrama de Arquitetura (Arquitetura + Ferramentas)

O diagrama abaixo representa nÃ£o apenas o fluxo lÃ³gico da arquitetura Medallion, mas tambÃ©m **as ferramentas utilizadas em cada etapa do pipeline**, deixando explÃ­cito o papel de cada tecnologia dentro da soluÃ§Ã£o.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Open Brewery DB API               â”‚
â”‚        (Fonte externa de dados REST)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Apache Airflow                â”‚
â”‚        OrquestraÃ§Ã£o e agendamento             â”‚
â”‚  - Scheduling                                 â”‚
â”‚  - Retries                                   â”‚
â”‚  - Error handling                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Bronze Layer                 â”‚
â”‚         Armazenamento Local (Docker)          â”‚
â”‚  - Python                                    â”‚
â”‚  - Requests                                  â”‚
â”‚  - Dados brutos (raw JSON)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Silver Layer                 â”‚
â”‚         Armazenamento Local (Docker)          â”‚
â”‚  - Python                                    â”‚
â”‚  - Pandas                                    â”‚
â”‚  - Limpeza e padronizaÃ§Ã£o                    â”‚
â”‚  - ValidaÃ§Ã£o de schema                       â”‚
â”‚  - OrganizaÃ§Ã£o por localizaÃ§Ã£o               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Gold Layer                  â”‚
â”‚         Armazenamento Local (Docker)          â”‚
â”‚  - Python                                    â”‚
â”‚  - AgregaÃ§Ãµes analÃ­ticas                     â”‚
â”‚  - Breweries por tipo e localizaÃ§Ã£o           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ğŸ“Œ **ObservaÃ§Ã£o:** Todas as camadas de dados sÃ£o atualmente persistidas em armazenamento local, executando dentro de containers Docker. Essa decisÃ£o foi tomada para evitar custos de cloud, mas a arquitetura foi pensada para permitir substituiÃ§Ã£o direta por serviÃ§os como **S3 / GCS / ADLS** sem grandes mudanÃ§as estruturais.

---

## ğŸ—ï¸ Camadas do Data Lake

### ğŸŸ¤ Bronze Layer

**Responsabilidade:**

* IngestÃ£o dos dados diretamente da API
* PersistÃªncia no formato bruto, sem transformaÃ§Ãµes estruturais

**DecisÃµes:**

* Manter o dado o mais prÃ³ximo possÃ­vel da fonte
* Facilitar reprocessamentos futuros

---

### âšª Silver Layer

**Responsabilidade:**

* Limpeza e padronizaÃ§Ã£o dos dados
* AplicaÃ§Ã£o de regras de qualidade
* TransformaÃ§Ã£o para estrutura tabular
* OrganizaÃ§Ã£o lÃ³gica para consumo posterior

**TransformaÃ§Ãµes realizadas:**

* SeleÃ§Ã£o e normalizaÃ§Ã£o de colunas
* ValidaÃ§Ãµes de schema
* Tratamento de valores nulos
* OrganizaÃ§Ã£o por atributos de localizaÃ§Ã£o

---

### ğŸŸ¡ Gold Layer

**Responsabilidade:**

* CriaÃ§Ã£o de uma visÃ£o analÃ­tica agregada

**Resultado:**

* Quantidade de cervejarias por **tipo** e **localizaÃ§Ã£o**
* Dataset pronto para consumo por ferramentas analÃ­ticas ou BI

---

## ğŸ”„ OrquestraÃ§Ã£o

O pipeline Ã© orquestrado utilizando **Apache Airflow**, escolhido por:

* Ampla adoÃ§Ã£o no mercado
* Facilidade de observabilidade via UI
* Suporte nativo a retries, SLA e dependÃªncias
* Clareza na modelagem do fluxo de dados

As DAGs estÃ£o organizadas de forma modular, refletindo as camadas do data lake.

---

## ğŸ§ª Testes

O projeto contempla testes automatizados, organizados em:

* **Testes unitÃ¡rios**: validaÃ§Ã£o de funÃ§Ãµes isoladas
* **Testes de integraÃ§Ã£o**: validaÃ§Ã£o do fluxo entre camadas
* **Testes de DAGs**: verificaÃ§Ã£o da estrutura e dependÃªncias do Airflow

Isso garante maior confiabilidade, facilidade de manutenÃ§Ã£o e seguranÃ§a para refatoraÃ§Ãµes.

---

## ğŸ³ ContainerizaÃ§Ã£o

Todo o ambiente Ã© executado via **Docker**, o que garante:

* Reprodutibilidade
* Facilidade de setup
* Isolamento de dependÃªncias

A escolha por Docker tambÃ©m atende ao critÃ©rio de modularizaÃ§Ã£o solicitado no case îˆ€fileciteîˆ‚turn0file0îˆ.

---

## âš–ï¸ Trade-offs e DecisÃµes de Engenharia

Durante o desenvolvimento, algumas decisÃµes foram tomadas considerando **escopo, tempo, custo e simplicidade operacional**, conforme esperado para um case tÃ©cnico.

---

### ğŸ—„ï¸ Trade-off: SQLite vs PostgreSQL (Metadata / Airflow)

No ambiente atual do projeto, foi utilizado **SQLite** como banco de metadados do Airflow.

**DecisÃ£o tomada:**

* Utilizar SQLite em vez de PostgreSQL

**Motivos:**

* Simplicidade de setup e execuÃ§Ã£o local
* ReduÃ§Ã£o de dependÃªncias e configuraÃ§Ã£o adicional
* Facilidade de reproduÃ§Ã£o do ambiente para avaliadores

**Trade-off assumido:**

* SQLite **nÃ£o Ã© recomendado para ambientes produtivos** ou de alta concorrÃªncia
* LimitaÃ§Ãµes de escalabilidade e concorrÃªncia

**CenÃ¡rio de produÃ§Ã£o:**

* A escolha adequada seria **PostgreSQL**, garantindo:

  * Maior robustez
  * Melhor suporte a concorrÃªncia
  * Maior confiabilidade para execuÃ§Ã£o paralela de DAGs

Essa decisÃ£o foi consciente e alinhada ao escopo do case, priorizando clareza e reprodutibilidade.

---

### â˜ï¸ Armazenamento

* **Atual:** armazenamento local
* **Trade-off:** simplicidade vs. escalabilidade
* **Justificativa:** evitar custos de cloud para um case tÃ©cnico

---

### ğŸ“Š Observabilidade

* **Atual:** logs e status nativos do Airflow
* **Trade-off:** implementaÃ§Ã£o simples vs. stack completa de monitoramento
* **Justificativa:** foco no pipeline funcional e correto

---

### âš™ï¸ Tecnologias

* NÃ£o foram utilizadas ferramentas como Delta Lake, Great Expectations ou serviÃ§os cloud gerenciados para manter o projeto acessÃ­vel e reproduzÃ­vel localmente.

---

## ğŸš€ Como Executar o Projeto

### PrÃ©-requisitos

* Docker
* Docker Compose

### Passos

```bash
# Clonar o repositÃ³rio
git clone https://github.com/Ricardo-Ikg/Breweries_case.git

# Entrar no projeto
cd Breweries_case

# Subir os containers
docker compose up -d
```

A interface do Airflow ficarÃ¡ disponÃ­vel em:

```
http://localhost:8080
```

---

## ğŸ”® Melhorias Futuras

Esta seÃ§Ã£o descreve evoluÃ§Ãµes naturais do pipeline para um ambiente de produÃ§Ã£o, considerando **boas prÃ¡ticas de Engenharia de Dados**, bem como os **trade-offs de escopo, custo e complexidade** discutidos durante o desenvolvimento do case.

---

### ğŸ“Š Data Quality (Qualidade de Dados)

O pipeline jÃ¡ possui um **primeiro nÃ­vel de Data Quality** por meio do uso de validaÃ§Ãµes de schema e regras implementadas com **Pandera**, garantindo:

* Conformidade de tipos de dados
* PresenÃ§a de colunas obrigatÃ³rias
* Regras bÃ¡sicas de consistÃªncia antes da promoÃ§Ã£o dos dados

Esse uso do Pandera pode ser considerado um **inÃ­cio de Data Quality**, focado em validaÃ§Ãµes estruturais e de schema.

Como evoluÃ§Ã£o futura, o processo poderia ser expandido para incluir:

* MÃ©tricas quantitativas de qualidade, como:

  * Percentual de registros invÃ¡lidos
  * Percentual de valores nulos por coluna
  * DistribuiÃ§Ã£o de valores inesperados
* PersistÃªncia dessas mÃ©tricas para anÃ¡lise histÃ³rica
* DefiniÃ§Ã£o de **quality gates** entre Silver e Gold

Essas melhorias aumentariam significativamente a **confiabilidade, governanÃ§a e observabilidade dos dados**.

---

### ğŸ“ˆ Monitoramento e Alertas

Em um cenÃ¡rio produtivo, o monitoramento poderia ser expandido para incluir:

* MÃ©tricas de execuÃ§Ã£o das DAGs:

  * Tempo de execuÃ§Ã£o por tarefa
  * Volume de dados processados
  * Taxa de falhas
* Alertas automÃ¡ticos para:

  * Falhas de DAG
  * Quebra de SLA
  * Anomalias de qualidade de dados

Exemplos de implementaÃ§Ã£o:

* IntegraÃ§Ã£o com **Datadog** para observabilidade centralizada (mÃ©tricas, logs e alertas)
* Alternativamente, uso de **Prometheus + Grafana** para coleta e visualizaÃ§Ã£o de mÃ©tricas
* Alertas via e-mail, Slack ou ferramentas corporativas

No escopo do case, optou-se por utilizar os **logs e status nativos do Airflow**, evitando aumento de complexidade operacional e custos adicionais.

---

### â˜ï¸ Armazenamento em Cloud (ADLS / S3 / GCS)

Uma evoluÃ§Ã£o natural do projeto seria mover o armazenamento local para um **data lake em cloud**, como:

* Azure Data Lake Storage (ADLS)
* Amazon S3
* Google Cloud Storage

BenefÃ­cios:

* SeparaÃ§Ã£o clara entre **compute e storage**
* Escalabilidade
* Maior resiliÃªncia

A nÃ£o implementaÃ§Ã£o no case se deu por **restriÃ§Ã£o de budget**, mantendo o projeto facilmente reproduzÃ­vel em ambiente local.

---

### âš™ï¸ Trade-off: Spark dentro do Airflow

Durante o desenho da soluÃ§Ã£o, foi considerado o uso de **Apache Spark** para processamento distribuÃ­do.

**DecisÃ£o tomada:**

* NÃ£o utilizar Spark neste case

**Motivos:**

* Volume de dados reduzido, nÃ£o justificando processamento distribuÃ­do
* Aumento significativo de complexidade operacional
* Overhead desnecessÃ¡rio para um pipeline batch simples

O Airflow foi utilizado **exclusivamente como orquestrador**, enquanto o processamento foi mantido em Python, respeitando o princÃ­pio de simplicidade e adequaÃ§Ã£o ao problema.

---

### â˜¸ï¸ Trade-off: NÃ£o utilizaÃ§Ã£o de Kubernetes

Embora Kubernetes seja amplamente utilizado em ambientes de dados modernos, ele nÃ£o foi adotado neste projeto pelos seguintes motivos:

* Complexidade operacional elevada para o escopo do case
* Overhead de setup e manutenÃ§Ã£o
* AusÃªncia de benefÃ­cios claros para um pipeline de batch simples

A escolha por **Docker Compose** garantiu:

* Reprodutibilidade
* Facilidade de execuÃ§Ã£o local
* Menor curva de aprendizado para avaliadores

Em um ambiente corporativo de larga escala, Kubernetes poderia ser considerado para:

* Alta disponibilidade
* Escalonamento automÃ¡tico
* Ambientes multi-tenant

---

## ğŸ“Œ ConsideraÃ§Ãµes Finais

Este projeto demonstra uma abordagem sÃ³lida de Engenharia de Dados, com foco em organizaÃ§Ã£o, qualidade, clareza arquitetural e boas prÃ¡ticas de mercado.
